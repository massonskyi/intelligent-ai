name: codellama-7b-instruct
type: llama_cpp
model_path: /models/codellama-7b-instruct.Q4_K_M.gguf
params:
  n_ctx: 4096
  n_threads: 16
  n_gpu_layers: 20
temperature: 0.7
top_p: 0.95
